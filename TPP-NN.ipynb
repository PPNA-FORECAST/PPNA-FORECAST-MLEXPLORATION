{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported modules.\n"
     ]
    }
   ],
   "source": [
    "#Load the imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "# The following lines adjust the granularity of reporting.\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "print(\"Imported modules.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define program constants\n",
    "\n",
    "DATABASE_PATH = \"database.csv\"\n",
    "SEQUENCE_LEN = 26 #26 points equals 26*15 days equals a year aprox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "aux_df = pd.read_csv(DATABASE_PATH)\n",
    "scale_factor = 1000.0\n",
    "# Shuffle the examples\n",
    "#train_df = train_df.reindex(np.random.permutation(train_df.index))\n",
    "#print(aux_df[['date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_timestamp(date_str):\n",
    "\n",
    "    if(isinstance(aux_df['date'][0], np.int64)):\n",
    "      print(\"Already converted\")\n",
    "      return False #NOT ROBUST, FAILS IF RUN TWICE ON THE SAME DF\n",
    "\n",
    "    date_obj = datetime.strptime(date_str, \"%m/%d/%Y\")\n",
    "    return int(date_obj.timestamp())# * 1000) Optional multiplication by 1000 to turn into miliseconds.\n",
    "\n",
    "\n",
    "aux_df['date'] = aux_df['date'].apply(convert_to_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978318000\n",
      "2001 1 1\n"
     ]
    }
   ],
   "source": [
    "#Check if dates are correctly turned into a timsetamp format\n",
    "print(aux_df['date'][0])\n",
    "date = datetime.fromtimestamp(aux_df['date'][0])\n",
    "year = date.year\n",
    "month = date.month\n",
    "day = date.day\n",
    "\n",
    "print(year, month, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the dataframe into three sections (train, test, validation) with roughly a 70-20-10 distribution\n",
    "#The samples are divided secuentially to improve the RNN performance\n",
    "\n",
    "train_df, test_df = train_test_split(aux_df, test_size=0.2, shuffle=False)  # 80% to training df and 20% to testing df\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, shuffle=False)  # Of the 80%, 90% goes to training and 10% to validation\n",
    "\n",
    "# To make each df legth divisible by the batches in the model building section\n",
    "train_df = train_df[:-(len(train_df) % SEQUENCE_LEN)]\n",
    "val_df = val_df[:-(len(val_df) % SEQUENCE_LEN)]\n",
    "test_df = test_df[:-(len(test_df) % SEQUENCE_LEN)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA NORMALIZATION INFO\n",
    "\n",
    "https://medium.com/@spinjosovsky/normalize-data-before-or-after-split-of-training-and-testing-data-7b8005f81e26\n",
    "https://datascience.stackexchange.com/questions/27615/should-we-apply-normalization-to-test-data-as-well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of every dataframe. The chosen normalization uses mean and standard deviation\n",
    "# Every Dataframe must be normalized by the same values, hence the train df mean and deviation are saved\n",
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "\n",
    "def normalize_data(data, mean, std):\n",
    "    return (data - mean) / std\n",
    "\n",
    "#The id field shouldn't be normalized yet is not used in the model\n",
    "train_normalized = normalize_data(train_df, train_mean, train_std)\n",
    "val_normalized = normalize_data(val_df, train_mean, train_std)\n",
    "test_normalized = normalize_data(test_df, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Input tensors of float values.\n",
    "#The prediction is going to use one value for lat, long, precipitation, temperature (the ones on the date desired to estimate)\n",
    "#and the SEQUENCE_LEN previous values of ppna\n",
    "inputs = {\n",
    "    'date':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='date'),\n",
    "    'latitude':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='latitude'),\n",
    "    'longitude':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='longitude'),\n",
    "    'ppna':\n",
    "        tf.keras.layers.Input(shape=(SEQUENCE_LEN, 1), dtype=tf.float32,\n",
    "                             name='ppna'),\n",
    "    'precipitation':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='precipitation'),\n",
    "    'temperature':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='temperature')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " ppna (InputLayer)           [(None, 26, 1)]              0         []                            \n",
      "                                                                                                  \n",
      " date (InputLayer)           [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " latitude (InputLayer)       [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " longitude (InputLayer)      [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " precipitation (InputLayer)  [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " temperature (InputLayer)    [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)               (None, 64)                   16896     ['ppna[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 69)                   0         ['date[0][0]',                \n",
      " )                                                                   'latitude[0][0]',            \n",
      "                                                                     'longitude[0][0]',           \n",
      "                                                                     'precipitation[0][0]',       \n",
      "                                                                     'temperature[0][0]',         \n",
      "                                                                     'lstm_5[0][0]']              \n",
      "                                                                                                  \n",
      " ppna_output (Dense)         (None, 1)                    70        ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16966 (66.27 KB)\n",
      "Trainable params: 16966 (66.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model for the NN\n",
    "# LSTM layer with 64 nodes processing the ppna -- the only parameter that takes info from the past\n",
    "lstm_layer = tf.keras.layers.LSTM(64)(inputs['ppna'])\n",
    "\n",
    "# Concatenate the inputs and LSTM output to provide the model tools to learn the patterns\n",
    "concatenated_features = tf.keras.layers.concatenate([inputs['date'], inputs['latitude'], inputs['longitude'], inputs['precipitation'], inputs['temperature'], lstm_layer])\n",
    "\n",
    "# Output Layer, with just one output (Estimated PPNA) that receives the concatenated features\n",
    "output = tf.keras.layers.Dense(1, name='ppna_output')(concatenated_features)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7763/7763 [==============================] - 71s 7ms/step - loss: 0.0073 - mae: 0.0187 - accuracy: 0.0000e+00 - val_loss: 3.2754e-06 - val_mae: 0.0013 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "7763/7763 [==============================] - 57s 7ms/step - loss: 3.3021e-06 - mae: 0.0011 - accuracy: 0.0000e+00 - val_loss: 2.4426e-06 - val_mae: 0.0013 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "7763/7763 [==============================] - 51s 7ms/step - loss: 2.4075e-06 - mae: 8.9188e-04 - accuracy: 0.0000e+00 - val_loss: 6.5731e-07 - val_mae: 4.8099e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "7763/7763 [==============================] - 64s 8ms/step - loss: 1.9573e-06 - mae: 8.0809e-04 - accuracy: 0.0000e+00 - val_loss: 4.5341e-07 - val_mae: 4.0556e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "7763/7763 [==============================] - 57s 7ms/step - loss: 1.7982e-06 - mae: 7.5696e-04 - accuracy: 0.0000e+00 - val_loss: 7.6339e-07 - val_mae: 6.6204e-04 - val_accuracy: 0.0000e+00\n",
      "4312/4312 [==============================] - 26s 6ms/step - loss: 8.4605e-07 - mae: 6.5426e-04 - accuracy: 0.0000e+00\n",
      "Pérdida en el conjunto de prueba: [8.460481240035733e-07, 0.0006542647606693208, 0.0]\n"
     ]
    }
   ],
   "source": [
    "#Model training\n",
    "\n",
    "#Define the training parameters\n",
    "epochs = 5  \n",
    "batch_size = 64 \n",
    "\n",
    "#Define the features and labels for each section of the process.\n",
    "#The label is the ppna (what we want to predict)\n",
    "#The features are the values used to predict said label (previous ppna, precipitations, temperature, lat, long, date)\n",
    "train_labels = train_normalized['ppna'] \n",
    "train_features = {\n",
    "        'date': train_normalized['date'],\n",
    "        'latitude': train_normalized['latitude'],\n",
    "        'longitude': train_normalized['longitude'],\n",
    "        'ppna': train_normalized['ppna'],\n",
    "        'precipitation': train_normalized['ppt'],\n",
    "        'temperature': train_normalized['temp']\n",
    "}\n",
    "\n",
    "val_labels = val_normalized['ppna'] \n",
    "val_features = {\n",
    "         'date': val_normalized['date'],\n",
    "         'latitude': val_normalized['latitude'],\n",
    "         'longitude': val_normalized['longitude'],\n",
    "         'ppna': val_normalized['ppna'],\n",
    "         'precipitation': val_normalized['ppt'],\n",
    "         'temperature': val_normalized['temp']\n",
    "}\n",
    "\n",
    "test_labels = test_normalized['ppna']\n",
    "test_features = {\n",
    "    'date': test_normalized['date'],\n",
    "    'latitude': test_normalized['latitude'],\n",
    "    'longitude': test_normalized['longitude'],\n",
    "    'ppna': test_normalized['ppna'],\n",
    "    'precipitation': test_normalized['ppt'],\n",
    "    'temperature': test_normalized['temp']\n",
    "}\n",
    "\n",
    "#Train the model with the previously defined parameters and data\n",
    "history = model.fit(\n",
    "    train_features, \n",
    "    train_labels, \n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(val_features, val_labels)  \n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss = model.evaluate(test_features, test_labels)  \n",
    "\n",
    "print(\"Pérdida en el conjunto de prueba:\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DE ACA PARA ABAJO SOLO HAY CODIGO SIN USAR, PARTES SIN PROBAR QUE GUARDE POR SI FALLA LO QUE HICE. NO EJECUTAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the model for the NN\n",
    "# CODIGO ALTERNATIVO PARA CREAR MODELO. NO EJECUTAR\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "num_caracteristicas = 6  # Número de características: PPNA, temperatura, precipitaciones, latitud, longitud, fecha\n",
    "\n",
    "# Modelo RNN con capa LSTM\n",
    "model = models.Sequential()\n",
    "\n",
    "# Agrega una capa LSTM con return_sequences=True para mantener las secuencias\n",
    "model.add(layers.LSTM(units=64, return_sequences=True, input_shape=(SEQUENCE_LEN, num_caracteristicas)))\n",
    "# Agrega otra capa LSTM si es necesario\n",
    "model.add(layers.LSTM(units=64, return_sequences=False))  # False para la última capa LSTM\n",
    "\n",
    "# Capa de salida para predecir la PPNA futura\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "# Compila el modelo\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3882/3882 [==============================] - 1008s 260ms/step - loss: 6.7000e-06 - mae: 0.0015 - val_loss: 2.8992e-06 - val_mae: 9.4896e-04\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer \"model_2\" expects 5 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor: shape=(32, 7), dtype=float64, numpy=\narray([[ 2.1170918 , -1.72874062, -0.26278911, -1.0814139 ,  0.82817595,\n        -0.20319931,  1.27145415],\n       [ 2.11709878, -1.72115296, -0.26278911, -1.0814139 ,  0.55131022,\n         0.05242548,  1.11048984],\n       [ 2.11710575, -1.7135653 , -0.26278911, -1.0814139 ,  0.17709505,\n         0.34331331,  1.1605987 ],\n       [ 2.11711272, -1.70597764, -0.26278911, -1.0814139 ,  0.03009318,\n         0.04313373,  1.61463614],\n       [ 2.1171197 , -1.69838998, -0.26278911, -1.0814139 , -0.18994747,\n         0.21244649,  1.18319312],\n       [ 2.11712667, -1.69080232, -0.26278911, -1.0814139 , -0.63195058,\n         0.17178716,  0.20023021],\n       [ 2.11713364, -1.68321466, -0.26278911, -1.0814139 , -0.57984389,\n         0.49953076,  0.14986643],\n       [ 2.11714062, -1.675627  , -0.26278911, -1.0814139 , -0.9956881 ,\n         0.11779576, -0.93057008],\n       [ 2.11714759, -1.66803934, -0.26278911, -1.0814139 , -1.19978138,\n        -0.10995097, -1.17504765],\n       [ 2.11715456, -1.66045168, -0.26278911, -1.0814139 , -1.39002985,\n         0.72040991, -0.26615302],\n       [ 2.11716154, -1.65286402, -0.26278911, -1.0814139 , -1.34903534,\n        -0.45188887, -1.25513637],\n       [ 2.11716851, -1.64527636, -0.26278911, -1.0814139 , -1.26089933,\n        -0.44737682, -1.11498983],\n       [ 2.11717548, -1.6376887 , -0.26278911, -1.0814139 , -1.08385888,\n        -0.83966125, -1.57708464],\n       [ 2.11718245, -1.63010104, -0.26278911, -1.0814139 , -0.88798217,\n        -0.88288877, -0.61576694],\n       [ 2.11718943, -1.62251338, -0.26278911, -1.0814139 , -0.84386072,\n         0.45315453, -0.60497468],\n       [ 2.1171964 , -1.61492572, -0.26278911, -1.0814139 , -0.6045983 ,\n        -0.02354208, -0.89508757],\n       [ 2.11720337, -1.60733806, -0.26278911, -1.0814139 , -0.35601736,\n        -0.73094639, -0.67810823],\n       [ 2.11721035, -1.5997504 , -0.26278911, -1.0814139 , -0.25718676,\n         1.10457807, -0.40504544],\n       [ 2.11721732, -1.59216274, -0.26278911, -1.0814139 ,  0.22059042,\n         2.4038059 ,  0.10347988],\n       [ 2.11722429, -1.58457508, -0.26278911, -1.0814139 ,  0.95765561,\n        -0.11696433,  0.03536864],\n       [ 2.11723127, -1.57698742, -0.26278911, -1.0814139 ,  1.43864063,\n         0.51632468,  0.29431591],\n       [ 2.11723824, -1.56939976, -0.26278911, -1.0814139 ,  1.68589306,\n        -0.82409914,  0.3492372 ],\n       [ 2.11724521, -1.5618121 , -0.26278911, -1.0814139 ,  1.85208203,\n         0.02055322,  1.05888231],\n       [ 2.11725219, -1.55564712, -0.26278911, -1.0814139 ,  1.65748913,\n        -0.50233552,  0.88270383],\n       [ 2.11725916, -1.54805946, -0.26278911, -1.0814139 ,  1.83980155,\n         1.50317396,  1.19714052],\n       [ 2.11726613, -1.5404718 , -0.26278911, -1.0814139 ,  1.35560892,\n        -0.48439045,  0.68929272],\n       [ 2.1172731 , -1.53288414, -0.26278911, -1.0814139 ,  0.61915079,\n         0.42112023,  0.81921141],\n       [ 2.11728008, -1.52529648, -0.26278911, -1.0814139 , -0.19576803,\n         1.74270117,  1.17868132],\n       [ 2.11728705, -1.51770882, -0.26278911, -1.0814139 , -0.4425675 ,\n         0.57451325,  0.14009126],\n       [ 2.11729402, -1.51012116, -0.26278911, -1.0814139 , -0.64090496,\n         2.43839923, -0.04058567],\n       [ 2.117301  , -1.5025335 , -0.26278911, -1.0814139 , -0.95470186,\n         1.26884827, -0.71197221],\n       [ 2.11730797, -1.49494584, -0.26278911, -1.0814139 , -1.12951111,\n         0.40741638, -0.35388862]])>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Tomas Bartol\\Documents\\FIUBA\\TPP\\NN-Code\\TPP-NN.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Tomas%20Bartol/Documents/FIUBA/TPP/NN-Code/TPP-NN.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tomas%20Bartol/Documents/FIUBA/TPP/NN-Code/TPP-NN.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     x\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mlatitude\u001b[39m\u001b[39m'\u001b[39m: train_normalized[\u001b[39m'\u001b[39m\u001b[39mlatitude\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tomas%20Bartol/Documents/FIUBA/TPP/NN-Code/TPP-NN.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mlongitude\u001b[39m\u001b[39m'\u001b[39m: train_normalized[\u001b[39m'\u001b[39m\u001b[39mlongitude\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tomas%20Bartol/Documents/FIUBA/TPP/NN-Code/TPP-NN.ipynb#X14sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tomas%20Bartol/Documents/FIUBA/TPP/NN-Code/TPP-NN.ipynb#X14sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tomas%20Bartol/Documents/FIUBA/TPP/NN-Code/TPP-NN.ipynb#X14sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Evalúa el modelo en el conjunto de prueba\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tomas%20Bartol/Documents/FIUBA/TPP/NN-Code/TPP-NN.ipynb#X14sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m test_loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mevaluate(test_normalized, test_labels)  \u001b[39m# Reemplaza test_labels por las etiquetas reales\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tomas%20Bartol/Documents/FIUBA/TPP/NN-Code/TPP-NN.ipynb#X14sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# Imprime el resultado de la evaluación\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tomas%20Bartol/Documents/FIUBA/TPP/NN-Code/TPP-NN.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPérdida en el conjunto de prueba:\u001b[39m\u001b[39m\"\u001b[39m, test_loss)\n",
      "File \u001b[1;32mc:\\Users\\Tomas Bartol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Tomas Bartol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py:219\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    214\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInputs to a layer should be tensors. Got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(x)\u001b[39m}\u001b[39;00m\u001b[39m) as input for layer \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    218\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputs) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(input_spec):\n\u001b[1;32m--> 219\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    220\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m expects \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(input_spec)\u001b[39m}\u001b[39;00m\u001b[39m input(s),\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m but it received \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(inputs)\u001b[39m}\u001b[39;00m\u001b[39m input tensors. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInputs received: \u001b[39m\u001b[39m{\u001b[39;00minputs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m     )\n\u001b[0;32m    224\u001b[0m \u001b[39mfor\u001b[39;00m input_index, (x, spec) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(inputs, input_spec)):\n\u001b[0;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m spec \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Layer \"model_2\" expects 5 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor: shape=(32, 7), dtype=float64, numpy=\narray([[ 2.1170918 , -1.72874062, -0.26278911, -1.0814139 ,  0.82817595,\n        -0.20319931,  1.27145415],\n       [ 2.11709878, -1.72115296, -0.26278911, -1.0814139 ,  0.55131022,\n         0.05242548,  1.11048984],\n       [ 2.11710575, -1.7135653 , -0.26278911, -1.0814139 ,  0.17709505,\n         0.34331331,  1.1605987 ],\n       [ 2.11711272, -1.70597764, -0.26278911, -1.0814139 ,  0.03009318,\n         0.04313373,  1.61463614],\n       [ 2.1171197 , -1.69838998, -0.26278911, -1.0814139 , -0.18994747,\n         0.21244649,  1.18319312],\n       [ 2.11712667, -1.69080232, -0.26278911, -1.0814139 , -0.63195058,\n         0.17178716,  0.20023021],\n       [ 2.11713364, -1.68321466, -0.26278911, -1.0814139 , -0.57984389,\n         0.49953076,  0.14986643],\n       [ 2.11714062, -1.675627  , -0.26278911, -1.0814139 , -0.9956881 ,\n         0.11779576, -0.93057008],\n       [ 2.11714759, -1.66803934, -0.26278911, -1.0814139 , -1.19978138,\n        -0.10995097, -1.17504765],\n       [ 2.11715456, -1.66045168, -0.26278911, -1.0814139 , -1.39002985,\n         0.72040991, -0.26615302],\n       [ 2.11716154, -1.65286402, -0.26278911, -1.0814139 , -1.34903534,\n        -0.45188887, -1.25513637],\n       [ 2.11716851, -1.64527636, -0.26278911, -1.0814139 , -1.26089933,\n        -0.44737682, -1.11498983],\n       [ 2.11717548, -1.6376887 , -0.26278911, -1.0814139 , -1.08385888,\n        -0.83966125, -1.57708464],\n       [ 2.11718245, -1.63010104, -0.26278911, -1.0814139 , -0.88798217,\n        -0.88288877, -0.61576694],\n       [ 2.11718943, -1.62251338, -0.26278911, -1.0814139 , -0.84386072,\n         0.45315453, -0.60497468],\n       [ 2.1171964 , -1.61492572, -0.26278911, -1.0814139 , -0.6045983 ,\n        -0.02354208, -0.89508757],\n       [ 2.11720337, -1.60733806, -0.26278911, -1.0814139 , -0.35601736,\n        -0.73094639, -0.67810823],\n       [ 2.11721035, -1.5997504 , -0.26278911, -1.0814139 , -0.25718676,\n         1.10457807, -0.40504544],\n       [ 2.11721732, -1.59216274, -0.26278911, -1.0814139 ,  0.22059042,\n         2.4038059 ,  0.10347988],\n       [ 2.11722429, -1.58457508, -0.26278911, -1.0814139 ,  0.95765561,\n        -0.11696433,  0.03536864],\n       [ 2.11723127, -1.57698742, -0.26278911, -1.0814139 ,  1.43864063,\n         0.51632468,  0.29431591],\n       [ 2.11723824, -1.56939976, -0.26278911, -1.0814139 ,  1.68589306,\n        -0.82409914,  0.3492372 ],\n       [ 2.11724521, -1.5618121 , -0.26278911, -1.0814139 ,  1.85208203,\n         0.02055322,  1.05888231],\n       [ 2.11725219, -1.55564712, -0.26278911, -1.0814139 ,  1.65748913,\n        -0.50233552,  0.88270383],\n       [ 2.11725916, -1.54805946, -0.26278911, -1.0814139 ,  1.83980155,\n         1.50317396,  1.19714052],\n       [ 2.11726613, -1.5404718 , -0.26278911, -1.0814139 ,  1.35560892,\n        -0.48439045,  0.68929272],\n       [ 2.1172731 , -1.53288414, -0.26278911, -1.0814139 ,  0.61915079,\n         0.42112023,  0.81921141],\n       [ 2.11728008, -1.52529648, -0.26278911, -1.0814139 , -0.19576803,\n         1.74270117,  1.17868132],\n       [ 2.11728705, -1.51770882, -0.26278911, -1.0814139 , -0.4425675 ,\n         0.57451325,  0.14009126],\n       [ 2.11729402, -1.51012116, -0.26278911, -1.0814139 , -0.64090496,\n         2.43839923, -0.04058567],\n       [ 2.117301  , -1.5025335 , -0.26278911, -1.0814139 , -0.95470186,\n         1.26884827, -0.71197221],\n       [ 2.11730797, -1.49494584, -0.26278911, -1.0814139 , -1.12951111,\n         0.40741638, -0.35388862]])>]"
     ]
    }
   ],
   "source": [
    "#Model training NO EJECUTAR, CODIGO BORRADOR\n",
    "\n",
    "epochs = 1  \n",
    "batch_size = 128  # Tamaño del lote de entrenamiento (ajusta según sea necesario)\n",
    "train_labels = train_normalized['ppna']\n",
    "val_labels = val_normalized['ppna']\n",
    "\n",
    "test_labels = test_normalized['ppna']\n",
    "test_features = {\n",
    "    'latitude': test_normalized['latitude'],\n",
    "    'longitude': test_normalized['longitude'],\n",
    "    'ppna': test_normalized['ppna'],\n",
    "    'precipitation': test_normalized['ppt'],\n",
    "    'temperature': test_normalized['temp']\n",
    "}\n",
    "\n",
    "history = model.fit(\n",
    "    x={'latitude': train_normalized['latitude'],\n",
    "       'longitude': train_normalized['longitude'],\n",
    "       'ppna': train_normalized['ppna'],\n",
    "       'precipitation': train_normalized['ppt'],\n",
    "       'temperature': train_normalized['temp']},\n",
    "    y=train_labels,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(\n",
    "        {'latitude': val_normalized['latitude'],\n",
    "         'longitude': val_normalized['longitude'],\n",
    "         'ppna': val_normalized['ppna'],\n",
    "         'precipitation': val_normalized['ppt'],\n",
    "         'temperature': val_normalized['temp']},\n",
    "        val_labels\n",
    "    )\n",
    ")\n",
    "\n",
    "# Evalúa el modelo en el conjunto de prueba\n",
    "test_loss = model.evaluate(test_features, test_labels)  # Reemplaza test_labels por las etiquetas reales\n",
    "\n",
    "# Imprime el resultado de la evaluación\n",
    "print(\"Pérdida en el conjunto de prueba:\", test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
